{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39fab749",
   "metadata": {},
   "source": [
    "### Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce316292",
   "metadata": {},
   "source": [
    "### Building credit card fraud detection model, using machine learning algorithms. \n",
    "Companies suffer losses due to fraudulent activities, many companies worldwide have lost billions of dollars yearly.\n",
    "This project aims to use the combination of fraud and non-fraud transactions from the historical data with different people's credit card transaction data to estimate fraud or non-fraud on credit card transactions.\n",
    "It is a classification supervised learning exercise and different models have been employed and imbalance in data addressed to arrive at the best possible classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de670d7",
   "metadata": {},
   "source": [
    "### Importing libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88bcfe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad54360",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd=pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f084f70",
   "metadata": {},
   "source": [
    "### Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec4c1170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d40cda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "fd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8e0522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645107ab",
   "metadata": {},
   "source": [
    "#### Dataset has 284807 rows and 31 features. The result of the shape variable is a tuple that has the number of rows, number of columns of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75763d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      " Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
      "       'Class'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Column names:\\n',fd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d8803c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6dd75",
   "metadata": {},
   "source": [
    "#### The target variable Class has 0 and 1 values. Here\n",
    "\n",
    "0 for non-fraudulent transactions\n",
    "1 for fraudulent transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1373e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be425947",
   "metadata": {},
   "source": [
    "#### There is an imbalance in the dataset as seen from the value counts above and will affect the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824c93e6",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fdf15a",
   "metadata": {},
   "source": [
    "#### Preprocessing is the process of cleaning the dataset. In this step, we will apply different methods to clean the raw data to feed more meaningful data for the modeling phase. This method includes\n",
    "\n",
    "    #Removing duplicates or irrelevant samples\n",
    "    #Updating missing values with the most relevant values \n",
    "    #Convert one data type to another example, categorical to integers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b737f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = fd.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6132451",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few values of Amount column after applying StandardScaler:- \n",
      " 0    0.244964\n",
      "1   -0.342475\n",
      "2    1.160686\n",
      "3    0.140534\n",
      "Name: norm_amount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "fd['norm_amount'] = StandardScaler().fit_transform(fd['Amount'].values.reshape(-1,1))\n",
    "fd = fd.drop(['Amount'], axis=1)\n",
    "print(f\"few values of Amount column after applying StandardScaler:- \\n {fd['norm_amount'][0:4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29c4640",
   "metadata": {},
   "source": [
    "### Splitting dependent and independent features and train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7b71f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fd.drop(['Class'], axis=1)\n",
    "y = fd[['Class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cf852aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199364, 29)\n",
      "(85443, 29)\n",
      "(199364, 1)\n",
      "(85443, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108d002",
   "metadata": {},
   "source": [
    "### Our project  falls under the supervised learning category i.e. the dataset has a target value for each row or sample in the dataset. \n",
    "#### Credit card fraud detection is a classification problem. Target variable values of Classification problems have integer(0,1) or categorical values(fraud, non-fraud). The target variable of our dataset ‘Class’ has only two labels - 0 (non-fraudulent) and 1 (fraudulent\n",
    "    #The decision tree algorithm considers all the provided features of the data and comes up with important features.\n",
    "    #The random forest algorithm falls under the ensemble learning algorithm category. In the random forest algorithm, we        build N decision tree model\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2d276b",
   "metadata": {},
   "source": [
    "### DECISION TREE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63caff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    "    # initialize object for DecisionTreeClassifier class\n",
    "    dt_classifier = DecisionTreeClassifier()\n",
    "    # train model by using fit method\n",
    "    print(\"Model training starts........\")\n",
    "    dt_classifier.fit(X_train, y_train.values.ravel()) \n",
    "    #ravel is used to change a 2-dimensional array or a multi-dimensional array into a contiguous flattened array.\n",
    "    print(\"Model training completed\")\n",
    "    acc_score = dt_classifier.score(X_test, y_test)\n",
    "    print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "    # predict result using test dataset\n",
    "    y_pred = dt_classifier.predict(X_test)\n",
    "    # confusion matrix\n",
    "    print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "    # classification report for f1-score\n",
    "    print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32adae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9992158515033414\n",
      "Confusion Matrix :- \n",
      " [[85266    30]\n",
      " [   37   110]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.79      0.75      0.77       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.89      0.87      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calling decision_tree_classification method to train and evaluate model\n",
    "decision_tree_classification(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1e580",
   "metadata": {},
   "source": [
    "#### Although accuracy is at 0.99% the f1-score at 0.77 is less, owing to the imbalanced data , as discussed earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6750daef",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efd13859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    "     # initialize object for DecisionTreeClassifier class\n",
    "     rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    "     # train model by using fit method\n",
    "     print(\"Model training starts........\")\n",
    "     rf_classifier.fit(X_train, y_train.values.ravel())\n",
    "     acc_score = rf_classifier.score(X_test, y_test)\n",
    "     print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    "     # predict result using test dataset\n",
    "     y_pred = rf_classifier.predict(X_test)\n",
    "     # confusion matrix\n",
    "     print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    "     # classification report for f1-score\n",
    "     print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac302435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training starts........\n",
      "Accuracy of model on test dataset :- 0.9994967405170698\n",
      "Confusion Matrix :- \n",
      " [[85290     6]\n",
      " [   37   110]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.95      0.75      0.84       147\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.87      0.92     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calling random_forest_classifier\n",
    "random_forest_classifier(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc942919",
   "metadata": {},
   "source": [
    "#### Accuracy is high but recall and f1score is low owing to unbalanced data, which  means one class label samples are  higher and dominating the other class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cd0385",
   "metadata": {},
   "source": [
    "#### TREATMENT OF UNBALANCED DATA\n",
    "We can use any of the below-mentioned metrics for unbalanced or skewed datasets.\n",
    "\n",
    "Recall\n",
    "Precision\n",
    "F1-score\n",
    "Area Under ROC curve\n",
    "\n",
    "Confusion Matrix\n",
    "True Positive (TP):-  \n",
    "The number of positive labels correctly predicted by trained models.  \n",
    "This means the number of Class-1 samples correctly predicted as Class-1.\n",
    "\n",
    "True Negative (TN):-\n",
    "The number of negative labels correctly predicted by trained models.  \n",
    "This means the number of Class-0 samples correctly predicted as Class-0.\n",
    "\n",
    "False Positive (FP):-  \n",
    "The number of positive labels incorrectly predicted by trained models. \n",
    "This means the number of Class-1 samples incorrectly predicted as Class-0.\n",
    "\n",
    "False Negative (FN):-  \n",
    "The number of negative labels incorrectly predicted by trained models. \n",
    "This means the number of Class-0 samples incorrectly predicted as Class-1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a25d28",
   "metadata": {},
   "source": [
    "#### Area Under ROC curve is another evaluation metric for classification problems. \n",
    "This is mostly suitable for skewed datasets.\n",
    "It tells us about model performance, such as the model's capability to distinguish between target classes. \n",
    "\n",
    "The effective model has a higher Area Under the ROC curve value. \n",
    "Here we measure the ability of class separability of a model by using the Area Under ROC curve.\n",
    "\n",
    "Good models have AUC value near to 1, and the worst models have AUC value near 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6acc9cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each class :- \n",
      " 0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n",
      "Non Fraudulent Numbers :- 284315\n",
      "Fraudulent Numbers :- 492\n"
     ]
    }
   ],
   "source": [
    "class_val = fd['Class'].value_counts()\n",
    "print(f\"Number of samples for each class :- \\n {class_val}\")\n",
    "non_fraud = class_val[0]\n",
    "fraud = class_val[1]\n",
    "print(f\"Non Fraudulent Numbers :- {non_fraud}\")\n",
    "print(f\"Fraudulent Numbers :- {fraud}\")\n",
    "# Equal both the target samples to the same level\n",
    "# take indexes of non fraudulent\n",
    "nonfraud_indexies = fd[fd.Class == 0].index\n",
    "fraud_indices = np.array(fd[fd['Class'] == 1].index)\n",
    "# take random samples from non fraudulent that are equal to fraudulent samples\n",
    "random_normal_indexies = np.random.choice(nonfraud_indexies, fraud, replace=False)\n",
    "random_normal_indexies = np.array(random_normal_indexies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e30d8",
   "metadata": {},
   "source": [
    "### Undersampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23d3b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate both indices of fraud and non fraud\n",
    "under_sample_indices = np.concatenate([fraud_indices, random_normal_indexies])\n",
    "\n",
    "#extract all features from whole data for under sample indices only\n",
    "under_sample_data = fd.iloc[under_sample_indices, :]\n",
    "\n",
    "# now we have to divide under sampling data to all features & target\n",
    "x_undersample_data = under_sample_data.drop(['Class'], axis=1)\n",
    "y_undersample_data = under_sample_data[['Class']]\n",
    "# now split dataset to train and test datasets as before\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(\n",
    "x_undersample_data, y_undersample_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed8af28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.9035532994923858\n",
      "Confusion Matrix :- \n",
      " [[93 13]\n",
      " [ 6 85]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       106\n",
      "           1       0.87      0.93      0.90        91\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.91      0.90       197\n",
      "weighted avg       0.91      0.90      0.90       197\n",
      "\n",
      "AROC score :- \n",
      " 0.905712212315986\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier after applying undersampling technique\n",
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " dt_classifier = DecisionTreeClassifier()\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " dt_classifier.fit(X_train, y_train.values.ravel())\n",
    " print(\"Model training completed\")\n",
    " acc_score = dt_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = dt_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "# calling decision tree classifier function \n",
    "decision_tree_classification(X_train_sample, y_train_sample, \n",
    "X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5ea71b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Accuracy of model on test dataset :- 0.9441624365482234\n",
      "Confusion Matrix :- \n",
      " [[101   5]\n",
      " [  6  85]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       106\n",
      "           1       0.94      0.93      0.94        91\n",
      "\n",
      "    accuracy                           0.94       197\n",
      "   macro avg       0.94      0.94      0.94       197\n",
      "weighted avg       0.94      0.94      0.94       197\n",
      "\n",
      "AROC score :- \n",
      " 0.9434480613725896\n"
     ]
    }
   ],
   "source": [
    "## RandomForestClassifier after apply the undersampling techniques\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " rf_classifier.fit(X_train, y_train.values.ravel())\n",
    " acc_score = rf_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = rf_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " # area under roc curve\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "random_forest_classifier(X_train_sample, y_train_sample, X_test_sample, y_test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cdef64",
   "metadata": {},
   "source": [
    "### Oversampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f7141a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate both indices of fraud and non fraud\n",
    "over_sample_indices = np.concatenate([fraud_indices, random_normal_indexies])\n",
    "\n",
    "#extract all features from whole data for over sample indices only\n",
    "over_sample_data = fd.iloc[over_sample_indices, :]\n",
    "\n",
    "# now we have to divide over sampling data to all features & target\n",
    "x_oversample_data = over_sample_data.drop(['Class'], axis=1)\n",
    "y_oversample_data = over_sample_data[['Class']]\n",
    "# now split dataset to train and test datasets as before\n",
    "X_traino_sample, X_testo_sample, y_traino_sample, y_testo_sample = train_test_split(\n",
    "x_oversample_data, y_oversample_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd0b52d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Model training completed\n",
      "Accuracy of model on test dataset :- 0.8984771573604061\n",
      "Confusion Matrix :- \n",
      " [[95 11]\n",
      " [ 9 82]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90       106\n",
      "           1       0.88      0.90      0.89        91\n",
      "\n",
      "    accuracy                           0.90       197\n",
      "   macro avg       0.90      0.90      0.90       197\n",
      "weighted avg       0.90      0.90      0.90       197\n",
      "\n",
      "AROC score :- \n",
      " 0.8986626580966204\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier after applying oversampling technique\n",
    "def decision_tree_classification(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " dt_classifier = DecisionTreeClassifier()\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " dt_classifier.fit(X_train, y_train.values.ravel())\n",
    " print(\"Model training completed\")\n",
    " acc_score = dt_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = dt_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "# calling decision tree classifier function \n",
    "decision_tree_classification(X_traino_sample, y_traino_sample, \n",
    "X_testo_sample, y_testo_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18e783e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training start........\n",
      "Accuracy of model on test dataset :- 0.9593908629441624\n",
      "Confusion Matrix :- \n",
      " [[102   4]\n",
      " [  4  87]]\n",
      "Classification Report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       106\n",
      "           1       0.96      0.96      0.96        91\n",
      "\n",
      "    accuracy                           0.96       197\n",
      "   macro avg       0.96      0.96      0.96       197\n",
      "weighted avg       0.96      0.96      0.96       197\n",
      "\n",
      "AROC score :- \n",
      " 0.9591540534936762\n"
     ]
    }
   ],
   "source": [
    "## RandomForestClassifier after apply the oversampling techniques\n",
    "\n",
    "def random_forest_classifier(X_train, y_train, X_test, y_test):\n",
    " # initialize object for DecisionTreeClassifier class\n",
    " rf_classifier = RandomForestClassifier(n_estimators=50)\n",
    " # train model by using fit method\n",
    " print(\"Model training start........\")\n",
    " rf_classifier.fit(X_train, y_train.values.ravel())\n",
    " acc_score = rf_classifier.score(X_test, y_test)\n",
    " print(f'Accuracy of model on test dataset :- {acc_score}')\n",
    " # predict result using test dataset\n",
    " y_pred = rf_classifier.predict(X_test)\n",
    " # confusion matrix\n",
    " print(f\"Confusion Matrix :- \\n {confusion_matrix(y_test, y_pred)}\")\n",
    " # classification report for f1-score\n",
    " print(f\"Classification Report :- \\n {classification_report(y_test, y_pred)}\")\n",
    " # area under roc curve\n",
    " print(f\"AROC score :- \\n {roc_auc_score(y_test, y_pred)}\")\n",
    "\n",
    "random_forest_classifier(X_traino_sample, y_traino_sample, X_testo_sample, y_testo_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749a5ac",
   "metadata": {},
   "source": [
    "#### For the best models, we have the AROC value near to 1. Here we implemented the undersampling & oversampling technique to address imbalance in data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075bf3a4",
   "metadata": {},
   "source": [
    "## Conclusion :Finally, our oversampling Random Forest classifier,model gives 95% of the Area Under the ROC curve value. We can improve model results by adding more trees or applying additional data preprocessing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9802dfe7",
   "metadata": {},
   "source": [
    "### Source code:https://dataaspirant.com/credit-card-fraud-detection-classification-algorithms-python/#:~:text=The%20credit%20card%20fraud%20classification%20problem%20is%20used,become%20a%20major%20problem%20to%20credit%20card%20companies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
